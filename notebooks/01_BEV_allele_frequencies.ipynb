{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making allele frequency plots\n",
    "\n",
    "This notebook contains code to process the CRISPResso \"allele frequency table\" files from base editor validation experiments. The inputs are 2 input files: the first contains metainformation about each sample to make the \"allele frequency\" file, and the second contains metainformation to compute correlations between the log-normalized read counts. The output of this file are 3 files for each sgRNA / primer pair: \n",
    "1. a file containing all alleles and their read counts for each sample\n",
    "2. a filtered version of (1) that only contains alleles with at least 1% abundance in any sample\n",
    "3. a file containing the Pearson correlations between log-normalized read counts of each allele with > 100 reads in at least one sample\n",
    "\n",
    "(1) is the starting file used to show the abundance of specific edits over time (code in BEV_aa_over_time.ipynb). (2) is the starting file used to create allele-level heatmaps (this was done using GraphPad Prism). (3) is the starting file for the plots showing the replicate correlation for validation experiments (actual plots were made using GraphPad Prism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2639576189652882659() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2639576189652882659()\">Show/Hide Toggle Function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(toggle_text_addon = '', for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "    \n",
    "    toggle_text = 'Show/Hide' + ' ' + toggle_text_addon  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "hide_toggle(toggle_text_addon='Toggle Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import core_functions as cfs\n",
    "from math import log\n",
    "from os import path\n",
    "import itertools\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "print('Python version: ' + sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.2.1\n",
      "numpy 1.19.5\n"
     ]
    }
   ],
   "source": [
    "modules = ['pandas', 'numpy']\n",
    "for module in modules:\n",
    "    try:\n",
    "        print(module + ' ' + sys.modules[module].__version__)\n",
    "    except:\n",
    "        print(module + ' has no __version__ attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9043258276326836127() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9043258276326836127()\">Show/Hide clean_input_file function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This function removes any NaN rows from input_file\n",
    "'''\n",
    "def clean_input_file(df):\n",
    "    df = df.dropna() #drop NaN \n",
    "    #dropna() converts int to float, so convert them back\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns #select subset of df of type float\n",
    "    for col in float_cols: \n",
    "        #get original column index so can replace at correct loc\n",
    "        index = df.columns.get_loc(col)\n",
    "        #rename float cols as \"float_\"col name \n",
    "        float_col_name = 'float_' + col\n",
    "        df = df.rename(columns = {col : float_col_name})\n",
    "        #overwrite as type int\n",
    "        float_to_int = df[float_col_name].astype(int).copy()\n",
    "        df.insert(index, col, float_to_int)\n",
    "        #drop float column \n",
    "        df = df.drop(float_col_name, axis = 1)\n",
    "    return df\n",
    "\n",
    "hide_toggle(toggle_text_addon='clean_input_file function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6603227828157682733() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6603227828157682733()\">Show/Hide remove_utr function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Called from: process_data_v2\n",
    "Function: removes UTRs from Aligned_Sequence before translation\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "translation_ref_seq: reference sequence from input file with intron sequence indicated by lowercase \n",
    "aligned: Aligned_sequence from merge df \n",
    "rev_com: True (from input file) if sequence needs to be reverse complemented \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "new_aligned: aligned sequence without UTRs and reverse complemented if necessary \n",
    "\n",
    "'''\n",
    "def remove_utr(translation_ref_seq, aligned, rev_com):\n",
    "    if ('[' not in translation_ref_seq) and (']' not in translation_ref_seq): # if no UTR\n",
    "        return\n",
    "    intron_flag = False # default value for intron flag is False\n",
    "    if any(char for char in translation_ref_seq if char.islower()): # check for any introns\n",
    "        intron_flag = True\n",
    "        translation_ref_seq = translation_ref_seq.upper()\n",
    "    \n",
    "    # check if number of open brackets equals number of closed brackets\n",
    "    if translation_ref_seq.count('[') != translation_ref_seq.count(']'):\n",
    "        print('Unequal number of open and closed brackets. Please make sure all brackets are closed.')\n",
    "        return\n",
    "    open_bracket = False # True when encounters open bracket [\n",
    "    closing_bracket = False # True when encounters closed bracket ]\n",
    "    in_utr = False # True when open_bracket == True and closing_bracket == False\n",
    "    utr_list = []\n",
    "    utr = ''\n",
    "    utr_start_end_list = []\n",
    "    start_end = [] \n",
    "    bracket_count = 0\n",
    "    # check to make sure all open brackets are only followed by closed, and closed is never followed by closed\n",
    "    for idx, char in enumerate(translation_ref_seq):\n",
    "        if char == '[':\n",
    "            if open_bracket: # if already encountered open bracket\n",
    "                print('Open bracket encountered after open bracket. Please make sure all brackets are closed.')\n",
    "                return\n",
    "            else:\n",
    "                open_bracket = True\n",
    "                closing_bracket = False\n",
    "                \n",
    "        if char == ']':\n",
    "            if open_bracket: # if this ] closes encountered open bracket\n",
    "                open_bracket = False\n",
    "                closing_bracket = True\n",
    "                bracket_count +=1 # count closed bracket \n",
    "                in_utr = False # end of UTR\n",
    "                utr_list.append(utr) # add UTR sequence to list\n",
    "#                 print(start_end)\n",
    "                # end idx = start idx + len(utr) - 1 (start index counted in length)\n",
    "                start_end.append(start_end[0]+len(utr)- 1)\n",
    "#                 print(start_end)\n",
    "#                 start_end.append(idx-bracket_count)# don't need to subtract # brackets encountered for closing\n",
    "                utr_start_end_list.append(start_end)\n",
    "                utr = '' # Reset UTR\n",
    "                start_end = [] # Rest start_end index pair\n",
    "                \n",
    "            elif closing_bracket: # if already encountered closing bracket\n",
    "                print('Closing bracket encountered after closing bracket. Please check input.')\n",
    "                return\n",
    "            else:\n",
    "                print('No open bracket encountered. Please check input.')\n",
    "                return\n",
    "        \n",
    "        if (open_bracket and not closing_bracket) and (char != '[') and (char != ']'):\n",
    "            in_utr = True \n",
    "            # if first character in utr, store start index\n",
    "            if len(utr) == 0:\n",
    "                bracket_count +=1 # count open bracket\n",
    "                start_end.append(idx-bracket_count) # subtract # brackets encountered\n",
    "            utr = utr + char\n",
    "    \n",
    "#     print('Translation ref seq UTR:', utr_list, 'UTR index pos:', utr_start_end_list)\n",
    "    \n",
    "    new_aligned = aligned \n",
    "    new_utrs = []\n",
    "    new_utr_start_end_list = []\n",
    "    # get length of translation_ref_seq without brackets\n",
    "    len_translation_ref_seq = len(translation_ref_seq.replace('[','').replace(']',''))\n",
    "    \n",
    "    if rev_com: # need to reverse complement UTR from translation_ref_seq to match aligned seq\n",
    "        # Reverse UTR index start, end positions if rev_com = True\n",
    "        for num, i in enumerate(utr_start_end_list):\n",
    "            start = i[0]\n",
    "            end = i[1]\n",
    "#             print('original start, end', start, end)\n",
    "            \n",
    "            new_idx_start = -(end+1) # reverse index, +1 b/c starts at -1 in reverse\n",
    "#             print(new_idx_start)\n",
    "            # convert to positive index by adding length of full translation_ref_seq (without brackets)\n",
    "            new_idx_start = len_translation_ref_seq + new_idx_start\n",
    "            # end index = start_index + length of utr - 1 (start index counted in length)\n",
    "            new_idx_end = new_idx_start + len(utr_list[num]) - 1\n",
    "#             print('new start, end', new_idx_start, new_idx_end)\n",
    "#             print(new_aligned[new_idx_start:new_idx_start + len(utr_list[num])])\n",
    "#             print('Translation ref seq start, end pos:', i, 'New aligned start, end pos:', new_idx_start, new_idx_end)\n",
    "#             print('New aligned UTR based on rev_com positions:')\n",
    "#             print(new_aligned[new_idx_start:new_idx_end])\n",
    "            new_utr_start_end_list.append([new_idx_start, new_idx_end])\n",
    "#       \n",
    "        for utr in utr_list:\n",
    "            rev_com_utr = cfs.revcom(utr)\n",
    "            new_utrs.append(rev_com_utr)\n",
    "    else:\n",
    "        new_utr_start_end_list = utr_start_end_list\n",
    "        new_utrs = utr_list\n",
    "    \n",
    "    if intron_flag: # if sequence contains both UTR(s) and intron(s)\n",
    "        utr_df = pd.DataFrame()\n",
    "#         print(new_utr_start_end_list)\n",
    "        for i, start_end in enumerate(new_utr_start_end_list):\n",
    "            utr_df.loc[i, 'start'] = int(start_end[0])\n",
    "            utr_df.loc[i, 'end'] = int(start_end[1])\n",
    "            utr_df.loc[i, 'sequence'] = new_utrs[i].upper()\n",
    "            utr_df.loc[i, 'type'] = 'UTR'\n",
    "            \n",
    "        return utr_df\n",
    "    \n",
    "    else:\n",
    "#         print('new aligned', new_aligned)\n",
    "\n",
    "        len_prev_utr = 0\n",
    "        for idx, utr in enumerate(new_utrs):\n",
    "            # adjust start and end index based on length of prev UTR, because indices shift after removal of UTR\n",
    "            # if first UTR, len_prev_utr = 0\n",
    "            start_end_idx = new_utr_start_end_list[idx]\n",
    "    #         print(start_end_idx, len_prev_utr)\n",
    "            if not rev_com: # if rev_com, UTRs removed in from end of sequence then upstream so earlier indices not affected\n",
    "                start_end_idx = [start_end_idx[0]-len_prev_utr, start_end_idx[1]-len_prev_utr]\n",
    "    #         print(idx, start_end_idx, utr, new_aligned)\n",
    "            # Check if bases at utr positions in aligned seq match utr\n",
    "            new_aligned_utr = new_aligned[start_end_idx[0]:start_end_idx[1]+1]\n",
    "#             print('New aligned UTR:', new_aligned_utr)\n",
    "            if new_aligned_utr != utr:\n",
    "    #             print('not found')\n",
    "                new_aligned = 'UTR'\n",
    "                return new_aligned\n",
    "            else:\n",
    "    #             print('found')\n",
    "                # remove UTR based on index position \n",
    "                if start_end_idx[0] == 0: # if UTR at the beginning of new_aligned seq, keep substring after end_index\n",
    "                    new_aligned = new_aligned[start_end_idx[1]+1:]\n",
    "                else: # (bases until start index + bases after end index)\n",
    "                    new_aligned = new_aligned[:start_end_idx[0]]+new_aligned[start_end_idx[1]+1:]\n",
    "    #             print(new_aligned)\n",
    "                len_prev_utr = len_prev_utr+len(utr) \n",
    "\n",
    "        if rev_com: # Now that UTR has been found, reverse complement again so correct translation input\n",
    "            new_aligned = cfs.revcom(new_aligned)\n",
    "#         print('New aligned:', new_aligned)\n",
    "        return new_aligned\n",
    "\n",
    "hide_toggle(toggle_text_addon='remove_utr function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_10493530679546260424() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_10493530679546260424()\">Show/Hide remove_introns function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "'''\n",
    "Called from: process_data_v2\n",
    "Function: removes introns from Aligned_Sequence before translation\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "translation_ref_seq: reference sequence from input file with intron sequence indicated by lowercase \n",
    "aligned: Aligned_sequence from merge df \n",
    "rev_com: True (from input file) if sequence needs to be reverse complemented \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "new_aligned: aligned sequence without introns and reverse complemented if necessary \n",
    "\n",
    "'''\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "def remove_introns(translation_ref_seq, aligned, rev_com):\n",
    "#     if utr_flag: # if UTR present, remove UTRs first\n",
    "#         translation_input = remove_utr(translation_ref_seq, aligned, rev_com)\n",
    "#         utr_start_idx = \n",
    "#         print(aligned.find(translation_input))\n",
    "    utr_flag = False # default value for utr_flag is False\n",
    "    if ('[' in translation_ref_seq) or (']' in translation_ref_seq):\n",
    "        utr_flag = True\n",
    "        translation_ref_seq = translation_ref_seq.replace('[','').replace(']','')\n",
    "        \n",
    "    # get index positions of introns \n",
    "    intron_idx= [i for i, base in enumerate(translation_ref_seq) if base.islower()]\n",
    "#     print('Positions of lowercase characters:', intron_idx)\n",
    "    intron_idx_list = []\n",
    "    # Get consecutive indices to group indices for same intron\n",
    "    for k, g in groupby(enumerate(intron_idx), lambda ix : ix[0] - ix[1]):\n",
    "         intron_idx_list.append(list(map(itemgetter(1), g)))\n",
    "    \n",
    "    # if no introns, exit function\n",
    "    if not intron_idx_list:\n",
    "        #print('no introns')\n",
    "        return \n",
    "    \n",
    "    # Get sequence of intron to check for intronic mutations \n",
    "    introns = []\n",
    "    intron_start_end_list = []\n",
    "    for intron_idx_group in intron_idx_list:\n",
    "        intron_start = intron_idx_group[0]\n",
    "        intron_end = intron_idx_group[-1]\n",
    "        # store intron start and end index positions in pairs in list \n",
    "        intron_start_end_list.append([intron_idx_group[0], intron_idx_group[-1]])\n",
    "#         print(intron_start_end_list)\n",
    "        intron = translation_ref_seq[intron_start:intron_end+1]\n",
    "        introns.append(intron)\n",
    "#         print(introns)\n",
    "#     print('Original start and end positions of introns:', intron_start_end_list)\n",
    "    new_aligned = aligned.upper()\n",
    "    \n",
    "    new_intron_start_end_list = []\n",
    "    new_introns = []    \n",
    "\n",
    "    if rev_com:\n",
    "        # Reverse intron index positions if rev_com = True\n",
    "        for i in intron_start_end_list:\n",
    "            new_idx_start = -(i[1]+1) # reverse index\n",
    "            # convert to positive index\n",
    "            new_idx_start = len(translation_ref_seq) + new_idx_start\n",
    "            new_idx_end = -(i[0]+1) # reverse index\n",
    "            # convert to positive index\n",
    "            new_idx_end = len(translation_ref_seq) + new_idx_end\n",
    "            new_intron_start_end_list.append([new_idx_start, new_idx_end])\n",
    "#             print(i, new_intron_idx_list)\n",
    "        for i in introns:\n",
    "            rev_com_intron = cfs.revcom(i.upper())\n",
    "            new_introns.append(rev_com_intron)\n",
    "#             print(new_introns)\n",
    "#         print('New start and end positions of introns:', new_intron_start_end_list)\n",
    "    else:\n",
    "        new_intron_start_end_list = intron_start_end_list\n",
    "        new_introns = introns\n",
    "    \n",
    "    if utr_flag: # if sequence contains both UTR(s) and introns(s), pass data to combo function\n",
    "        intron_df = pd.DataFrame()\n",
    "#         print(new_utr_start_end_list)\n",
    "        for i, start_end in enumerate(new_intron_start_end_list):\n",
    "            intron_df.loc[i, 'start'] = int(start_end[0])\n",
    "            intron_df.loc[i, 'end'] = int(start_end[1])\n",
    "            intron_df.loc[i, 'sequence'] = new_introns[i].upper()\n",
    "            intron_df.loc[i, 'type'] = 'intron'\n",
    "        return intron_df\n",
    "\n",
    "    else:    \n",
    "#         print('Intron sequences:', new_introns)\n",
    "#         print('Aligned seq', new_aligned)\n",
    "        len_prev_intron = 0\n",
    "        for idx, intron in enumerate(new_introns):\n",
    "            # if not first intron, adjust start and end index based on length of prev intron\n",
    "            start_end_idx = new_intron_start_end_list[idx]\n",
    "            if not rev_com:\n",
    "                start_end_idx = [start_end_idx[0]-len_prev_intron, start_end_idx[1]-len_prev_intron]\n",
    "#                 print(start_end_idx, intron)\n",
    "            # Check if bases at intron positions in aligned seq match intron\n",
    "            if new_aligned[start_end_idx[0]:start_end_idx[1]+1] != intron.upper():\n",
    "    #             print('not found')\n",
    "                new_aligned = 'intron'\n",
    "                return new_aligned\n",
    "            else:\n",
    "    #             print('found')\n",
    "                # remove intron based on index position \n",
    "                if start_end_idx[0] == 0: # if intron at the beginning of new_aligned seq, keep substring after end_index\n",
    "                    new_aligned = new_aligned[start_end_idx[1]+1:]\n",
    "    #                 print(new_aligned)\n",
    "                else: # (bases until intron start index + bases after intron end index)\n",
    "                    new_aligned = new_aligned[:start_end_idx[0]]+new_aligned[start_end_idx[1]+1:]\n",
    "    #             print(new_aligned)\n",
    "                len_prev_intron = len_prev_intron + len(intron)\n",
    "    #     print(new_aligned)\n",
    "        if rev_com:\n",
    "            new_aligned = cfs.revcom(new_aligned)\n",
    "#         print('introns removed, new aligned:', new_aligned)\n",
    "        return new_aligned\n",
    "    \n",
    "hide_toggle(toggle_text_addon='remove_introns function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16868224634379944179() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16868224634379944179()\">Show/Hide remove_utr_intron_combo Full Function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_utr_intron_combo(translation_ref_seq, aligned, rev_com):\n",
    "#     print(translation_ref_seq.upper())\n",
    "    utr_df = remove_utr(translation_ref_seq, aligned, rev_com)\n",
    "    intron_df = remove_introns(translation_ref_seq, aligned, rev_com)\n",
    "    \n",
    "#     print(utr_df, intron_df)\n",
    "    # Store UTR and intron start/end positions and sequences in single df\n",
    "    removal_df = pd.concat([utr_df, intron_df]).sort_values(by='start').reset_index(drop=True)\n",
    "    \n",
    "    removal_df['start'] = removal_df['start'].copy().astype(int)\n",
    "    removal_df['end'] = removal_df['end'].copy().astype(int)\n",
    "    prev_start = 0\n",
    "    prev_end = 0\n",
    "    prev_type = ''\n",
    "#     print(removal_df)\n",
    "    # Check for overlaps\n",
    "#     for i, row in removal_df.iterrows():\n",
    "#         start = row['start']\n",
    "#         end = row['end']\n",
    "#         region_type = row['type']\n",
    "#         if start < prev_end: # if region starts in the middle of previous region\n",
    "# #             print(removal_df)\n",
    "#             if end > prev_end: # if region extends beyond end of previous region\n",
    "#                 overlap = prev_end - start + 1 # determine number of bases in region that overlap\n",
    "#                 new_region_seq = row['sequence'][overlap:]\n",
    "#                 removal_df.at[i, 'sequence'] = new_region_seq\n",
    "#                 start = prev_end + 1 # re-define start of region at position after end of previous region \n",
    "#                 removal_df.at[i, 'start'] = start\n",
    "#             else: # if region fully contained in previous region\n",
    "#                 # remove row because will be captured by previous region\n",
    "#                 removal_df = removal_df.copy().drop(i, axis=0)\n",
    "        \n",
    "#         prev_start = start\n",
    "#         prev_end = end\n",
    "#         prev_type = region_type\n",
    "    # re-index dataframe after adjusting for overlaps\n",
    "    removal_df = removal_df.copy().reset_index(drop=True)\n",
    "    \n",
    "#     print(removal_df)\n",
    "    \n",
    "    new_aligned = aligned\n",
    "    len_prev_removal = 0\n",
    "    \n",
    "    for idx, removal_seq in enumerate(removal_df['sequence']):\n",
    "        removal_row = removal_df.loc[idx, :]\n",
    "        # if not first removal region (UTR/intron), adjust start and end index based on length of prev removal\n",
    "        start_end_idx = [removal_row['start'], removal_row['end']]\n",
    "\n",
    "        # Since start positions are ordered in ascending order, adjust based on length of prev removal \n",
    "        # regardless of rev_com\n",
    "        # if not rev_com\n",
    "        start_end_idx = [start_end_idx[0]-len_prev_removal, start_end_idx[1]-len_prev_removal]\n",
    "#         print(start_end_idx, removal_seq)\n",
    "#         print(new_aligned[start_end_idx[0]:start_end_idx[1]+1])\n",
    "        # Check if bases at removal positions in aligned seq match removal_seq\n",
    "        if new_aligned[start_end_idx[0]:start_end_idx[1]+1] != removal_seq:\n",
    "# #             print('not found')\n",
    "            if removal_row['type'] == 'UTR':\n",
    "                new_aligned = 'UTR'\n",
    "            if removal_row['type'] == 'intron':\n",
    "                new_aligned = 'intron'\n",
    "            return new_aligned\n",
    "        else:\n",
    "#             print('found')\n",
    "            # remove region based on index position \n",
    "            if start_end_idx[0] == 0: # if region at the beginning of new_aligned seq, keep substring after end_index\n",
    "                new_aligned = new_aligned[start_end_idx[1]+1:]\n",
    "#                 print(new_aligned)\n",
    "            else: # (bases until intron start index + bases after intron end index)\n",
    "                new_aligned = new_aligned[:start_end_idx[0]]+new_aligned[start_end_idx[1]+1:]\n",
    "#             print(new_aligned)\n",
    "            len_prev_removal = len_prev_removal + len(removal_seq)\n",
    "#     print(new_aligned)\n",
    "    if rev_com:\n",
    "        new_aligned = cfs.revcom(new_aligned)\n",
    "#     print('regions removed, new aligned:', new_aligned)\n",
    "    return new_aligned\n",
    "\n",
    "\n",
    "hide_toggle(toggle_text_addon='remove_utr_intron_combo Full Function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2193220020272883193() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2193220020272883193()\">Show/Hide translate function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function returns the translation of a given sequence and frame\n",
    "def translate(seq, frame, first_codon, last_codon, codon_map):\n",
    "#     if not seq: # if remove_introns returned False -> possible splice site mutation\n",
    "    if seq == 'UTR':\n",
    "        return 'Possible UTR mutation'\n",
    "    if seq == 'intron':\n",
    "        return 'Possible intronic mutation'\n",
    "    aa = ''\n",
    "    i = 0\n",
    "    # if frame is not 1, add nucleotides necessary to beginning of sequence for translation based on first_codon\n",
    "    if frame == 2:\n",
    "        seq = first_codon[0] + seq\n",
    "        frame = 1\n",
    "    if frame == 3:\n",
    "        seq = first_codon[0:2] + seq\n",
    "        frame = 1\n",
    "\n",
    "#     print(seq)    \n",
    "    while i < len(seq):\n",
    "        substring = ''\n",
    "        while frame <= 3:\n",
    "            if i<len(seq):\n",
    "                if seq[i] == '-':\n",
    "                    #print('deletion')\n",
    "                    i += 1\n",
    "                    # frame doesn't change\n",
    "                else:\n",
    "                    substring += seq[i]  \n",
    "                    i += 1\n",
    "                    frame+=1\n",
    "            else: # if reached end of the sequence and frame still <=3, complete codon sequence based on last_codon\n",
    "                substring += last_codon[frame-1]\n",
    "                i += 1\n",
    "                frame+=1\n",
    "    \n",
    "#             print('substring:', substring, 'i = ', i, 'frame = ', frame)\n",
    "        if len(substring) == 3:\n",
    "            frame = 1 # reset frame \n",
    "            if ('N' in substring):\n",
    "                aa = aa + '-'\n",
    "            else:\n",
    "                aa = aa + codon_map[substring] # translate codon\n",
    "#             print(aa)\n",
    "        else:\n",
    "            frame = 1\n",
    "#         print(frame)\n",
    "    return aa\n",
    "\n",
    "codon_map = {'TTT':'F', 'TTC':'F', 'TTA':'L', 'TTG':'L', 'CTT':'L', 'CTC':'L', 'CTA':'L', 'CTG':'L', 'ATT':'I', 'ATC':'I',\n",
    "             'ATA':'I', 'ATG':'M', 'GTT':'V', 'GTC':'V', 'GTA':'V', 'GTG':'V', 'TCT':'S', 'TCC':'S', 'TCA':'S', 'TCG':'S',\n",
    "             'CCT':'P', 'CCC':'P', 'CCA':'P', 'CCG':'P', 'ACT':'T', 'ACC':'T', 'ACA':'T', 'ACG':'T', 'GCT':'A', 'GCC':'A',\n",
    "             'GCA':'A', 'GCG':'A', 'TAT':'Y', 'TAC':'Y', 'TAA':'*', 'TAG':'*', 'CAT':'H', 'CAC':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "             'AAT':'N', 'AAC':'N', 'AAA':'K', 'AAG':'K', 'GAT':'D', 'GAC':'D', 'GAA':'E', 'GAG':'E', 'TGT':'C', 'TGC':'C',\n",
    "             'TGA':'*', 'TGG':'W', 'CGT':'R', 'CGC':'R', 'CGA':'R', 'CGG':'R', 'AGT':'S', 'AGC':'S', 'AGA':'R', 'AGG':'R',\n",
    "             'GGT':'G', 'GGC':'G', 'GGA':'G', 'GGG':'G'}\n",
    "\n",
    "hide_toggle(toggle_text_addon='translate function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13547304780953818214() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13547304780953818214()\">Show/Hide input check functions</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_input_file(input_file):\n",
    "    \n",
    "    print('Checking input file...')\n",
    "    # Check each input column for correct formatting\n",
    "\n",
    "    err_flag = False\n",
    "\n",
    "    for i, row in tqdm(input_file.iterrows()):\n",
    "        translation_err_flag = False\n",
    "        utr_flag = False\n",
    "        intron_flag = False\n",
    "        sg = row['sg']\n",
    "        # sgRNA sequence must be all uppercase\n",
    "        sgRNA_seq = row['sgRNA_sequence'].upper()\n",
    "        # translation_ref_seq: use WT aligned condition to check formatting, frame, first codon, last codon\n",
    "        ref_seq = row['translation_ref_seq']\n",
    "        frame = row['frame']\n",
    "        # First and last codon must also be all uppercase (should be all coding)\n",
    "        first_codon = row['first_codon'].upper()\n",
    "        last_codon = row['last_codon'].upper()\n",
    "        \n",
    "        # Make sure there are only As, Cs, Gs, and Ts in the sequence inputs \n",
    "        sequence_inputs = [sgRNA_seq, ref_seq, first_codon, last_codon]\n",
    "        for seq in sequence_inputs:\n",
    "            chars_allowed = ['A', 'C', 'G', 'T', '[', ']']\n",
    "            non_nuc_char = [char for char in seq if char.upper() not in chars_allowed]\n",
    "            if non_nuc_char: # if there are any characters that are not A, C, G, or T or brackets\n",
    "                print('Invalid character in sequence. Please make sure the sequence only contains As, Cs, Gs, and Ts.')\n",
    "                return\n",
    "            else:\n",
    "                # Brackets only allowed in translation_ref_seq\n",
    "                if ((('[' in seq) or (']' in seq)) and (seq != ref_seq)):\n",
    "                    print('Invalid character in sequence. Brackets are only allowed in translation_ref_seq.')\n",
    "                    return\n",
    "                \n",
    "        \n",
    "        print('sg:', sg)\n",
    "        \n",
    "        input_file.loc[i, 'sgRNA_sequence'] = sgRNA_seq\n",
    "        \n",
    "        print('Translation reference sequence:', ref_seq)\n",
    "        WT_aligned_seq = ref_seq\n",
    "        brackets = '[]'\n",
    "        # if UTR in translation_ref_seq\n",
    "        if ('[' in ref_seq) or (']' in ref_seq):\n",
    "            utr_flag = True\n",
    "            for bracket in brackets:\n",
    "                WT_aligned_seq = WT_aligned_seq.replace(bracket, '')\n",
    "        if any(c.islower() for c in ref_seq):\n",
    "            intron_flag = True\n",
    "            WT_aligned_seq = WT_aligned_seq.upper()\n",
    "        \n",
    "        \n",
    "        translation_input = WT_aligned_seq\n",
    "\n",
    "        # Remove UTRs and/or introns if applicable to check frame, first codon, and last codon \n",
    "        # Since translation_ref_seq in correct orientation for translation, rev_com = False for this check\n",
    "        rev_com = False\n",
    "#         if utr_flag:\n",
    "#             translation_input = remove_utr(ref_seq, translation_input, rev_com)\n",
    "#         if intron_flag:\n",
    "# #             print(ref_seq, translation_input, rev_com)\n",
    "#             translation_input = remove_introns(ref_seq, translation_input, rev_com)\n",
    "        if utr_flag and intron_flag:\n",
    "            translation_input = remove_utr_intron_combo(ref_seq, translation_input, rev_com)\n",
    "        elif utr_flag:\n",
    "            translation_input = remove_utr(ref_seq, translation_input, rev_com)\n",
    "        elif intron_flag:\n",
    "#             print(ref_seq, translation_input, rev_com)\n",
    "            translation_input = remove_introns(ref_seq, translation_input, rev_com)\n",
    "        \n",
    "        # Match frame and translation_input with first codon to check if they match\n",
    "        translation_start_idx = frame - 1\n",
    "        print('Translation input:', translation_input)\n",
    "        # Check if first base in translation_input matches corresponding nucleotide in first codon based on frame \n",
    "    #     print(frame, translation_input[0], first_codon[translation_start_idx])\n",
    "        if translation_input[0] != first_codon[translation_start_idx]:\n",
    "            print(translation_input[0], first_codon[translation_start_idx])\n",
    "            print('Frame does not match base in first_codon. Please check inputs') \n",
    "            err_flag = True\n",
    "#             translation_err_flag = \n",
    "        else:\n",
    "            # Check if last codon in translation_ref_seq is complete\n",
    "            # length of translation_input - # bases in start codon present in translation_ref_seq\n",
    "            print(len(translation_input), translation_start_idx)\n",
    "            len_last_codon = (len(translation_input) - (3-translation_start_idx))%3 \n",
    "#             len_last_codon = (len(translation_input) - frame)%3 \n",
    "            print(len_last_codon)\n",
    "    #         print(len_last_codon, translation_input[-len_last_codon:])\n",
    "            if len_last_codon == 0:\n",
    "                if translation_input[-3:] != last_codon:\n",
    "                    print(translation_input[-3:], last_codon)\n",
    "                    print('Input for last_codon does not align with translation_ref_seq. Please check inputs.')\n",
    "                    err_flag = True\n",
    "            else:\n",
    "#                 print(translation_input, translation_input[-len_last_codon:], last_codon)\n",
    "                if translation_input[-len_last_codon:] != last_codon[:len_last_codon]:\n",
    "                    print(translation_input[-len_last_codon:], last_codon[:len_last_codon])\n",
    "                    print('Input for last_codon does not align with frame and translation_ref_seq. Please check inputs.')\n",
    "                    err_flag = True\n",
    "\n",
    "            if not err_flag:\n",
    "                print('Expected WT Translation: ', translate(translation_input, frame, first_codon, last_codon, codon_map))\n",
    "#         break\n",
    "    if not err_flag:\n",
    "        return('Input file is correct!')\n",
    "    else:\n",
    "        return('Please address errors listed above before proceeding.')\n",
    "    \n",
    "# Check to make sure folder filepaths are correctly formatted\n",
    "def check_folder_filepath(filepath):\n",
    "    # Check if filepath is relative\n",
    "    if not (path.isabs(filepath)):\n",
    "        # if relative, get rid of '/' at the beginning of filepath\n",
    "        if filepath[0] == '/':\n",
    "            filepath = filepath[1:]\n",
    "    if filepath[-1] != '/':\n",
    "        filepath = filepath+'/'\n",
    "    # Check if filepath exists\n",
    "    if path.exists(filepath):\n",
    "        return filepath\n",
    "    else:\n",
    "        raise ValueError('Filepath does not exist. Please check your inputs.')\n",
    "        return\n",
    "\n",
    "hide_toggle(toggle_text_addon='input check functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3527552883623301178() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3527552883623301178()\">Show/Hide process data functions</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Called from: process_data_v2\n",
    "Function: converts the BEV number from an int to a 3-digit string\n",
    "'''\n",
    "def get_bev_str(bev):\n",
    "    bev = int(bev)\n",
    "    if bev < 10:\n",
    "        return '00'+str(bev)\n",
    "    if bev < 100:\n",
    "        return '0'+str(bev)\n",
    "    return str(bev)\n",
    "'''\n",
    "Called from: get_path\n",
    "Function: Verifies existence of filepath generated by get_path function to retrieve 'Alleles_frequency_table_around_sgRNA' file\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "filepath : filepath to 'Alleles_frequency_table_around_sgRNA_[].txt' file in CRISPResso output folder, \n",
    "           from get_path function\n",
    "bev : BEV sample number \n",
    "sg_seq: guide sequence\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "file_loc : filepath of 'Alleles_frequency_table_around_sgRNA_[].txt' file if exists\n",
    "None if no filepath exists \n",
    "\n",
    "'''\n",
    "def check_filepath(filepath,bev,primer,sg_seq):\n",
    "    file_loc = filepath+'CRISPResso_on_'+bev+'_'+primer+'/'+'Alleles_frequency_table_around_sgRNA_'+sg_seq+'.txt'\n",
    "    print(file_loc)\n",
    "    if path.exists(file_loc):\n",
    "        return file_loc\n",
    "    else:\n",
    "        raise ValueError('File not found. Please check your filepath inputs.')\n",
    "        return ''\n",
    "\n",
    "'''\n",
    "Called from: get_bev_files\n",
    "Function: calls check_filepath to get filepath where CRISPResso output files are stored, \n",
    "whose folder path (CRISPResso_filepath) is provided above\n",
    "Calls: check_filepath\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "bev_num : BEV sample number\n",
    "primer: primer name (from input file)\n",
    "sg_seq: guide sequence\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "file_loc : filepath of 'Alleles_frequency_table_around_sgRNA_[].txt' file if exists\n",
    "None if no filepath exists \n",
    "\n",
    "'''\n",
    "\n",
    "def get_path(bev_num,primer,sg_seq):\n",
    "    bev = bev_string_id + '_' + get_bev_str(bev_num)\n",
    "    filepath = CRISPResso_filepath\n",
    "    return check_filepath(filepath,bev,primer,sg_seq)\n",
    "\n",
    "\n",
    "'''\n",
    "Called from: get_bev_files\n",
    "Function: merges together the \"Allele_frequency_table_around_sgRNA\" files\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "filepath : filepath to 'Alleles_frequency_table_around_sgRNA_[].txt' file in CRISPResso output folder, \n",
    "           from get_path function\n",
    "bev : BEV sample number \n",
    "sg_seq: guide sequence\n",
    "existing_df: merge data frame with 'Aligned_Sequence' and 'Reference_Sequence' columns defined in get_bev_files\n",
    "cols: empty list populated in function \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "merge : merged dataframe with Aligned_Sequence, Reference_Sequence, Reads columns from each sample \n",
    "cols: columns labeled with BEV sample number \n",
    "'''\n",
    "def merge_bev_file(filepath,bev,sg_seq,existing_df,cols):\n",
    "    if not path.exists(filepath):\n",
    "        print('no file')\n",
    "        return existing_df,cols\n",
    "    df = pd.read_table(filepath,index_col=False)\n",
    "    # Sum together any rows that share both 'Aligned Sequence' and 'Reference Sequence' with each other (this is rare)\n",
    "    df_summed = df[['Aligned_Sequence','Reference_Sequence','#Reads','%Reads']].groupby(['Aligned_Sequence','Reference_Sequence'],as_index=False).agg('sum')\n",
    "    cols.append(str('_BEV_'+str(bev)))\n",
    "    df_summed = df_summed.rename(columns={'#Reads':str('#Reads_BEV_'+str(bev)),'%Reads':str('%Reads_BEV_'+str(bev))})\n",
    "    # Outer merge onto existing dataframe\n",
    "    merge = pd.merge(existing_df,df_summed,how='outer',on=['Aligned_Sequence','Reference_Sequence'])\n",
    "    # Fill in nans with 0\n",
    "    merge = merge.fillna(0)\n",
    "    return merge,cols\n",
    "\n",
    "'''\n",
    "Called from: process_data_v2\n",
    "Function: function gets and merges all \"Allele_frequency_table_around_sgRNA\" files for a given sgRNA sequence\n",
    "(i.e. different replicates, drug conditions, etc.)\n",
    "This is customized to work with files with the \"BEV\" notation\n",
    "Calls: get_path, merge_bev_file\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "bev_list : contains BEV sample number, primer name, guide sequence for each sample  \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "merge: merged dataframe with \n",
    "cols:\n",
    "\n",
    "'''\n",
    "\n",
    "def get_bev_files(bev_list):\n",
    "    merge = pd.DataFrame(columns=['Aligned_Sequence','Reference_Sequence'])\n",
    "    cols = []\n",
    "    for bev,sg_seq,primer_name in bev_list:\n",
    "        filepath = get_path(bev,primer_name,sg_seq)\n",
    "        if filepath != '':\n",
    "            merge,cols = merge_bev_file(filepath=filepath,bev=bev,sg_seq=sg_seq,existing_df=merge,cols=cols)\n",
    "    return merge,cols\n",
    "\n",
    "'''\n",
    "Called from: process_data_v2\n",
    "Function: filters out rows that don't meet given threshold (<1% for %Reads and <100 for #Reads)\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "row : row in column to which function is being applied (%Reads or #Reads)\n",
    "cols: given cols (%Reads, #Reads for all samples )\n",
    "val: threshold for filter \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "returns False for any rows (alleles) that have a value < the given value in ALL of the given cols\n",
    "\n",
    "'''\n",
    "def read_count_filter(row,cols,val):\n",
    "    for col in cols:\n",
    "        if row[col] > val:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "'''\n",
    "This function checks for WT allele (if Aligned_Sequence = Reference_Sequence)\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "row : row of merge dataframe \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "returns True if the allele is unedited (i.e. WT) and False otherwise\n",
    "\n",
    "'''\n",
    "def get_wt_col(row):\n",
    "    if row['Aligned_Sequence'] == row['Reference_Sequence']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "'''\n",
    "This function calculates the LFC\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "row : row of metainformation input file containing BEV_test and BEV_ref columns\n",
    "data_file : merged dataframe containing log-normalized rpm for each allele\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "data_file : merged dataframe, now with LFC columns for each BEV test / ref pair\n",
    "\n",
    "'''\n",
    "def get_lfc_v2(row,data_file):\n",
    "    cols = []\n",
    "    bev_list = row['BEV_test'].split(';')\n",
    "    \n",
    "    # Go through each test sample in BEV_test column\n",
    "    for i,bev in enumerate(bev_list):\n",
    "        test = get_bev_str(bev)\n",
    "        \n",
    "        # Get reference sample for LFC from BEV_ref column\n",
    "        ref = get_bev_str(row['BEV_ref'].split(';')[i])\n",
    "        \n",
    "        # Calculate LFC\n",
    "        data_file['LFC_'+test+'-'+ref] = data_file['#Reads_BEV_'+test+';lognorm'] - data_file['#Reads_BEV_'+ref+';lognorm']  \n",
    "        cols.append('LFC_'+test+'-'+ref)\n",
    "        \n",
    "    # Average together LFC columns\n",
    "    data_file['AvgLFC_'+'_'.join(bev_list)] = data_file.loc[:,cols].mean(axis=1)\n",
    "    return data_file\n",
    "\n",
    "'''\n",
    "Called from: run\n",
    "Function: merges read counts (filtered), lognorms, aligned sequences, reference sequences, translations from \n",
    "test and reference samples for sgRNA \n",
    "\n",
    "INPUTS\n",
    "------\n",
    "data : deduplicated input file with column 'sg','BEV_start','BEV_end','sgRNA_sequence','primer','frame','rev_com'\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "merge : merged dataframe with filtered read counts, lognorms, aligned sequences, reference sequences, translations\n",
    "\n",
    "'''\n",
    "        \n",
    "def process_data_v2(data):\n",
    "    bev_list = [] # list to store info for retrieving CRISPResso files for given sgRNA\n",
    "    ref_nums = [] # list to store BEV numbers for CRISPResso files for reference samples \n",
    "    for i,row in data.iterrows():\n",
    "        for bev in range(row['BEV_start'],row['BEV_end']+1):\n",
    "            # store BEV number, sgRNA sequence, and primer name to get corresponding CRISPResso files \n",
    "            bev_list.append((get_bev_str(bev),row['sgRNA_sequence'],row['primer']))\n",
    "        \n",
    "        # if reference samples outside of BEV_start and BEV_end range, add to bev_list separately\n",
    "        BEV_ref = data['BEV_ref'].copy().tolist() #.copy.loc['BEV_ref']))\n",
    "        BEV_ref_split = BEV_ref[0].split(';')\n",
    "        for num in BEV_ref_split:\n",
    "            # check if reference sample numbers outside of BEV_start and BEV_end range\n",
    "            if ((int(num) < row['BEV_start']) | (int(num) > row['BEV_end'])):\n",
    "                ref_nums.append(num)\n",
    "            else:\n",
    "                continue\n",
    "        for ref_num in ref_nums:\n",
    "            # store BEV number, sgRNA sequence, and primer name to get corresponding CRISPResso files \n",
    "            bev_list.append((get_bev_str(ref_num),row['sgRNA_sequence'],row['primer']))\n",
    "        print(bev_list)\n",
    "    \n",
    "    # Call get_bev_files function which merges Alleles_frequency_tables_around_sgRNA for given sgRNA  \n",
    "    merge,cols = get_bev_files(bev_list)\n",
    "    \n",
    "    # Calculate log-normalized reads per million for each col\n",
    "    for col in ['#Reads'+col for col in cols]:\n",
    "        colsum = merge[col].sum()\n",
    "        merge.loc[:,str(col+';lognorm')] = merge[col].apply(lambda x: log((float(x)/float(colsum))*1000000 + 1,2))\n",
    "\n",
    "    print(['%Reads'+col for col in cols])\n",
    "    #changed to <2% for poor sequencing quality\n",
    "    # Apply read count filter\n",
    "    merge.loc[:,'%read_count_filter'] = merge.apply(read_count_filter,args=(['%Reads'+col for col in cols],2),axis=1) # less than 2% of all reads\n",
    "    merge.loc[:,'#read_count_filter'] = merge.apply(read_count_filter,args=(['#Reads'+col for col in cols],100),axis=1) # less than 100 reads\n",
    "    \n",
    "    # Before translating, check if there are introns and/or UTRs in translation_ref_seq column in input file\n",
    "    # introns indicated by lowercase letters in translation_ref_seq column \n",
    "    # UTRs indicated by square brackets in translation_ref_seq column \n",
    "    \n",
    "    # Returns true if intron in translation_ref_seq (i.e. if lowercase letters in input translation_ref_seq)\n",
    "    intron_flag = any(c.islower() for c in str(data.loc[data.index[0], 'translation_ref_seq']))\n",
    "    \n",
    "    # Returns true if UTR in translation_ref_seq (i.e. if square brackets in input translation_ref_seq)\n",
    "    utr_flag = any(c=='[' for c in str(data.loc[data.index[0], 'translation_ref_seq']))\n",
    "    \n",
    "#     print(intron_flag)\n",
    "    if utr_flag or intron_flag:\n",
    "        filtered_input_df = pd.DataFrame()\n",
    "        filtered_input_df['old_Aligned_Sequence'] = merge.loc[:,'Aligned_Sequence'].copy()\n",
    "        filtered_input_df['translation_ref_seq'] = data['translation_ref_seq'].to_list()[0]\n",
    "        filtered_input_df['rev_com'] = data.loc[i, 'rev_com']\n",
    "        \n",
    "    # If translated_ref_seq contains both UTRs and introns, call remove_utr_intron_combo function\n",
    "    if utr_flag and intron_flag:\n",
    "        print('both introns and UTRs exist')\n",
    "        filtered_input_df['Aligned_Sequence']= list(map(remove_utr_intron_combo, filtered_input_df['translation_ref_seq'], filtered_input_df['Aligned_Sequence'], filtered_input_df['rev_com']))\n",
    "    \n",
    "    # If translated_ref_seq contains only UTRs, call remove_utr function\n",
    "    elif utr_flag:\n",
    "        print('only UTRs exist')\n",
    "        \n",
    "        # Call remove_utrs function to remove UTRs from aligned sequence before translating \n",
    "        filtered_input_df['Aligned_Sequence']= list(map(remove_utr, filtered_input_df['translation_ref_seq'], filtered_input_df['old_Aligned_Sequence'].copy(), filtered_input_df['rev_com']))\n",
    "#         print(filtered_input_df)\n",
    "\n",
    "    # If translated_ref_seq contains only introns, call remove_introns function\n",
    "    elif intron_flag:\n",
    "        print('only introns exist')\n",
    "        # Call remove_introns function to remove introns from aligned sequence before translating \n",
    "        filtered_input_df['Aligned_Sequence']= list(map(remove_introns, filtered_input_df['translation_ref_seq'], filtered_input_df['old_Aligned_Sequence'], filtered_input_df['rev_com']))\n",
    "\n",
    "    # if introns or UTR in translation_ref_seq\n",
    "    if utr_flag or intron_flag: \n",
    "        # Call translate function to translate new (UTR-free and intron-free) sequence  \n",
    "        merge.loc[:,'Translated'] = filtered_input_df['Aligned_Sequence'].apply(translate, args =(row['frame'],row['first_codon'], row['last_codon'], codon_map,))\n",
    "    \n",
    "    # if no introns or UTR\n",
    "    else:\n",
    "        print('no UTRs or introns')\n",
    "        # check if Aligned Sequence needs to be reverse complemented before translating \n",
    "        rev_com = data.loc[i, 'rev_com']\n",
    "        if rev_com:\n",
    "            merge.loc[:,'Aligned_Sequence'] = merge.loc[:,'Aligned_Sequence'].apply(cfs.revcom)\n",
    "            merge.loc[:,'Reference_Sequence'] = merge.loc[:,'Reference_Sequence'].apply(cfs.revcom)\n",
    "        # Call translate function to translate Aligned Sequence (reverse complemented if necessary) \n",
    "        merge.loc[:,'Translated'] = merge.loc[:,'Aligned_Sequence'].apply(translate,args=(row['frame'],row['first_codon'], row['last_codon'], codon_map,))\n",
    "    \n",
    "#     print(merge['Translated'])\n",
    "    return merge\n",
    "'''\n",
    "Called from: run\n",
    "Function: joins all possible combinations of #Reads;lognorms columns from samples for given sgRNA \n",
    "\n",
    "INPUTS\n",
    "------\n",
    "row : #Reads;lognorm columns \n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "columns joined by '_' : '#Reads_BEV_#;lognorm column_#Reads_BEV_#;lognorm column'\n",
    "Ex. '#Reads_BEV_041;lognorm_#Reads_BEV_042;lognorm'  \n",
    "\n",
    "'''\n",
    "\n",
    "def get_corr_name(row):\n",
    "    cols = [row['R1'],row['R2']]\n",
    "    cols.sort()\n",
    "    return '_'.join(cols)\n",
    "\n",
    "'''\n",
    "Called from: run\n",
    "Function: gets combinations of samples specified in reps_for_correlation column in correlation input \n",
    "\n",
    "INPUTS\n",
    "------\n",
    "corr_input : correlation input file \n",
    "sg: guide identifier from corr_input\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "combos : '#Reads_BEV_#;lognorm column_#Reads_BEV_#;lognorm column' for pairs specified in corr_input  \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def get_correlation_cols(corr_input,sg):\n",
    "    corr_input = corr_input.loc[corr_input['sg'] == sg,:]\n",
    "    combos = []\n",
    "    for i,r in corr_input.iterrows():\n",
    "        bevs = r['reps_for_correlation'].split(';')\n",
    "        bevs = ['#Reads_BEV_'+get_bev_str(bev)+';lognorm' for bev in bevs]\n",
    "        if len(bevs) > 1:\n",
    "            combos.extend(itertools.combinations(bevs,2))\n",
    "    combos = ['_'.join(combo) for combo in combos]\n",
    "    return combos\n",
    "\n",
    "hide_toggle(toggle_text_addon='process data functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_14756489484948883341() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_14756489484948883341()\">Show/Hide run function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This function calls all previous functions to generate output tables \n",
    "\n",
    "INPUTS\n",
    "------\n",
    "input_file : input file with columns 'sg', 'translation_ref_seq', 'sgRNA_sequence', 'BEV_start', 'BEV_end', 'primer',\n",
    "       'frame', 'rev_com', 'BEV_ref', 'BEV_test' described above\n",
    "corr_input : input file with columns 'sg', 'reps_for_correlation' described above\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "output files stored in output_filepath given above\n",
    "\n",
    "'''\n",
    "\n",
    "def run(input_file,corr_input):\n",
    "    \n",
    "    # List of sgRNA identifiers provided in \"sg\" column of input file\n",
    "    sg_list = list(set(input_file['sg'].tolist())) # drop duplicates from list\n",
    "\n",
    "    # Go through each sgRNA separately    \n",
    "    for sg in sg_list:\n",
    "        print(sg)\n",
    "        \n",
    "        # Filter input file to contain only rows for given sgRNA\n",
    "        data = input_file.loc[input_file['sg'] == sg,:]\n",
    "        \n",
    "        # Merge all the allele read counts\n",
    "        # To do this, drop the BEV_test and BEV_ref columns (which just have information needed for the LFC calculation)\n",
    "        # Then drop duplicate rows\n",
    "        data_dedup = data.drop_duplicates(subset=['sg','BEV_start','BEV_end','sgRNA_sequence','primer','frame','rev_com'])\n",
    "        \n",
    "        # Call process_data_v2 function which adds the following columns to output table:\n",
    "        #read counts, lognorms, aligned sequences, reference sequences, translations \n",
    "        merge = process_data_v2(data_dedup)\n",
    "        \n",
    "        # Get the WT column\n",
    "        merge['WT'] = merge.apply(get_wt_col,axis=1)\n",
    "        \n",
    "#         print(merge[merge['WT']])\n",
    "        # Now, go through each row and calculate the LFC for each of the pairs specified in BEV_test and BEV_ref\n",
    "        for i,r in data.iterrows():               \n",
    "            merge = get_lfc_v2(r,merge)\n",
    "        print('num rows in merge df:', len(merge))\n",
    "        print(merge[merge['%read_count_filter'] == True])\n",
    "            \n",
    "        # Write out 2 files: full file (merge) and filtered file (only including alleles with > 2% reads in at least one condition)\n",
    "        Path(output_filepath).mkdir(parents=True, exist_ok=True)\n",
    "        merge.to_csv(output_filepath +str(r['sg'])+'_'+r['primer']+'_allele_frequency_table_around_sgRNA.csv',index=False)\n",
    "        filtered = merge[merge['%read_count_filter'] == True]\n",
    "        filtered.to_csv(output_filepath +str(r['sg'])+'_'+r['primer']+'_filtered_allele_frequency_table_around_sgRNA.csv',\n",
    "                        index=False)            \n",
    "        \n",
    "        filtered_adjusted_percentage = filtered.copy()\n",
    "        \n",
    "        # Adjust percentages in filtered table so they total 100% \n",
    "        \n",
    "        # Get #Reads columns from filtered table \n",
    "        num_reads_cols_all = [col for col in filtered_adjusted_percentage.columns if '#Reads' in col]\n",
    "        # List lognorm column names that are included in #Reads cols \n",
    "        lognorm_cols = [col for col in num_reads_cols_all if 'lognorm' in col]\n",
    "        # Drop lognorm columns \n",
    "        num_reads_cols = [col for col in num_reads_cols_all if col not in lognorm_cols]\n",
    "        percentage_reads_cols = []\n",
    "#         print(num_reads_cols)\n",
    "        \n",
    "        for col in num_reads_cols:\n",
    "            num_reads_col = col\n",
    "            sum_reads = filtered_adjusted_percentage[num_reads_col].sum()\n",
    "            print(sum_reads)\n",
    "#             percentage_reads_col ='%Reads_BEV_'+ get_bev_str(num)\n",
    "            percentage_reads_col = num_reads_col.replace('#', '%')\n",
    "            percentage_reads_cols.append(percentage_reads_col)\n",
    "            for i in filtered_adjusted_percentage.index:\n",
    "                num_reads = filtered_adjusted_percentage.loc[i, num_reads_col]\n",
    "                adjusted_percentage_reads = (num_reads/sum_reads) * 100 \n",
    "                filtered_adjusted_percentage.at[i, percentage_reads_col] = adjusted_percentage_reads\n",
    "        \n",
    "        # Drop rows with %Reads < 1% after adjustment \n",
    "        filtered_adjusted_percentage_2 = filtered_adjusted_percentage.copy()\n",
    "        for col in percentage_reads_cols:\n",
    "            filtered_adjusted_percentage_2 = filtered_adjusted_percentage_2[filtered_adjusted_percentage_2[col]>1].copy()\n",
    "\n",
    "        # Make sure WT is included\n",
    "        if filtered_adjusted_percentage_2[filtered_adjusted_percentage_2['WT'].eq(True)].empty:\n",
    "            WT_row = filtered_adjusted_percentage[filtered_adjusted_percentage['WT'].eq(True)]\n",
    "            filtered_adjusted_percentage_2 = pd.concat([filtered_adjusted_percentage_2.copy(), WT_row])\n",
    "\n",
    "        filtered_adjusted_percentage_2.to_csv(output_filepath +str(r['sg'])+'_'+r['primer']+'_filtered_adj_percentage_allele_frequency_table_around_sgRNA.csv',\n",
    "                index=False) \n",
    "\n",
    "        # Get correlations matrix of log-normalized rpm, using only alleles with > 100 reads in at least one sample\n",
    "        merge = merge[merge['#read_count_filter'] == True]\n",
    "        cols = [x for x in list(merge) if 'lognorm' in x]\n",
    "        correlations = merge[cols].corr(method='pearson')\n",
    "        correlations['R1'] = correlations.index\n",
    "        correlations = correlations.melt(id_vars = 'R1', value_vars=list(correlations).remove('R1'),var_name='R2',value_name='Pearson')\n",
    "        \n",
    "        # Drop correlations that are not specified in corr_input\n",
    "        correlations['Reps'] = correlations.apply(get_corr_name,axis=1)\n",
    "        combos = get_correlation_cols(corr_input,sg)\n",
    "        correlations = correlations[correlations['Reps'].isin(combos)]\n",
    "        \n",
    "        # Drop duplicate rows (i.e. A vs B and B vs A)\n",
    "        correlations = correlations.drop_duplicates(subset=['Reps'])\n",
    "        \n",
    "        # Write to file\n",
    "        Path(output_filepath + \"corr_outputs/#read_count_filter_pearson/\").mkdir(parents=True, exist_ok=True)\n",
    "        correlations.to_csv(output_filepath + \"corr_outputs/#read_count_filter_pearson/sg\" +str(r['sg'])+'_'+r['primer']+'_correlations.csv')\n",
    "#         break\n",
    "    return \n",
    "\n",
    "hide_toggle(toggle_text_addon='run function')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11279445231156632537() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11279445231156632537()\">Show/Hide heatmap function</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "rcParams['font.family'] = 'monospace' #so translated sequences are aligned\n",
    "rcParams['font.monospace'] = 'Arial'\n",
    "rcParams['font.size']: 12.0\n",
    "\n",
    "'''\n",
    "This function generates allele-level heatmaps using log-fold changes for each validation condtion\n",
    "annotated with the corresponding allele amino acid sequences\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "df : input file with columns 'sg', 'translation_ref_seq', 'sgRNA_sequence', 'BEV_start', 'BEV_end', 'primer',\n",
    "       'frame', 'rev_com', 'BEV_ref', 'BEV_test' described above\n",
    "vmin : sets minimum value for heatmap color bar\n",
    "vmax: sets maximum value for heatmap color bar\n",
    "filepath: same as output_filepath specified above where allele frequency output tables are saved \n",
    "time1: (optional) string describing early time point for table header, e.g. 'Day7' (default: 'Time1')\n",
    "time2: (optional) string describing late time point for table header, e.g. 'Day14' (default: 'Time2')\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "1. allele-level heatmpas with corresponding allele amino acid sequences annotated\n",
    "2. tables with average % reads for each allele at early and late time points \n",
    "\n",
    "'''\n",
    "\n",
    "def heatmaps(df,vmin,vmax,filepath, time1 = 'Time1', time2 = 'Time2', timepoint_df=None, filename = 'translation_heatmap', **kwargs):\n",
    "\n",
    "    num_rows = len(df)\n",
    "    num_cols = 2\n",
    "    fig,axs = plt.subplots(num_rows, num_cols, figsize=(num_cols*4,num_rows*4))\n",
    "    plt.subplots_adjust(wspace=0.5, hspace = 0.5)\n",
    "    \n",
    "    row_count = 0\n",
    "    \n",
    "    for num, (i,r) in enumerate(df.iterrows()):\n",
    "\n",
    "        sg = r['sg']\n",
    "#         print('before plot sg: ', sg)\n",
    "        primer = r['primer']\n",
    "#         location = filepath+str(sg)+'_'+primer+'_filtered_allele_frequency_table_around_sgRNA.csv'\n",
    "        location = filepath+str(sg)+'_'+primer+'_filtered_adj_percentage_allele_frequency_table_around_sgRNA.csv'\n",
    "\n",
    "        to_plot = pd.read_csv(location)\n",
    "\n",
    "        avgLFC_col = [col for col in to_plot.columns if 'AvgLFC' in col][0]\n",
    "\n",
    "        to_plot.sort_values(by=avgLFC_col,ascending=False,inplace=True)\n",
    "        \n",
    "        # Earlier time point -> Time1\n",
    "        time1_avg_col = 'Avg%Reads_' + time1\n",
    "        \n",
    "        # Later time point -> Time 2\n",
    "        time2_avg_col = 'Avg%Reads_' + time2\n",
    "        \n",
    "        if timepoint_df is None: # Default to BEV_ref as Time1 samples and BEV_test as Time2 samples\n",
    "            \n",
    "            # Default Time 1 (Earlier time point) samples  = BEV_ref columns \n",
    "            time1_samples = r['BEV_ref'].split(';') # convert to list of BEV numbers\n",
    "\n",
    "            # Default Time 2 (Later time point) samples  = BEV_ref columns \n",
    "            time2_samples = r['BEV_test'].split(';') # convert to list of BEV numbers \n",
    "            \n",
    "        else: # if timepoint_df provided\n",
    "            # Get Time 1 columns from df based on time1 parameter \n",
    "            sg_timepoint_df = timepoint_df[timepoint_df['sg']==sg]\n",
    "            time1_sample_df = sg_timepoint_df[sg_timepoint_df['time_point']==time1].reset_index(drop=True)\n",
    "            time1_samples = time1_sample_df.loc[0, 'BEV_nums'].split(';')\n",
    "            \n",
    "            # Get Time 2 columns from df based on time2 parameter \n",
    "            sg_timepoint_df = timepoint_df[timepoint_df['sg']==sg]\n",
    "            time2_sample_df = sg_timepoint_df[sg_timepoint_df['time_point']==time2].reset_index(drop=True)\n",
    "            time2_samples = time2_sample_df.loc[0, 'BEV_nums'].split(';')\n",
    "        \n",
    "        # Lists to store correctly formatted %Reads column names \n",
    "        time1_cols = [] \n",
    "        time2_cols = []\n",
    "        \n",
    "        # %Reads columns named \"%Reads_BEV_\" + get_bev_str(int(BEV_num))\n",
    "        for num in time1_samples:\n",
    "            col_name = \"%Reads_BEV_\" + get_bev_str(int(num))\n",
    "            time1_cols.append(col_name)  \n",
    "\n",
    "        to_plot[time1_avg_col] = round(to_plot[time1_cols].apply(np.mean,axis=1),1).apply(str)#+'%'\n",
    "\n",
    "        # %Reads columns named \"%Reads_BEV_\" + get_bev_str(int(BEV_num))\n",
    "        for num in time2_samples:\n",
    "            col_name = \"%Reads_BEV_\" + get_bev_str(int(num))\n",
    "            time2_cols.append(col_name)  \n",
    "\n",
    "        to_plot[time2_avg_col] = round(to_plot[time2_cols].apply(np.mean,axis=1),1).apply(str)#+'%'\n",
    "\n",
    "        to_plot['Label'] = to_plot['Translated']\n",
    "\n",
    "        reads_df = to_plot[[time1_avg_col, time2_avg_col]]\n",
    "\n",
    "        to_plot.loc[to_plot['WT'],'Label'] = to_plot.loc[to_plot['WT'],'Label'].values[0] + '<wt' \n",
    "\n",
    "        heatmap_df = to_plot[['Label',[col for col in to_plot.columns if 'AvgLFC' in col][0]]].reset_index(drop = True)\n",
    "        \n",
    "        if row_count < num_rows:\n",
    "            # HEATMAP\n",
    "            if num_rows == 1: \n",
    "                heatmap_ax = axs[0]\n",
    "            else: \n",
    "                heatmap_ax = axs[row_count, 0]\n",
    "            \n",
    "            cmap = LinearSegmentedColormap.from_list(name='test', colors=['#8DA0CB','white','#F8774F'])\n",
    "            sns.heatmap(heatmap_df.set_index('Label'),cmap=cmap,vmin=vmin,vmax=vmax,ax=heatmap_ax,annot=True, yticklabels = True, fmt='.1f')\n",
    "            label_list = [item for item in heatmap_ax.get_yticklabels()]\n",
    "            for label in label_list:\n",
    "                if '<wt' in label.get_text():\n",
    "                    label.set_color('red')\n",
    "            plt.setp(heatmap_ax.get_yticklabels(), rotation=0, ha=\"left\", size = 12)#,rotation_mode=\"anchor\")\n",
    "\n",
    "            yax = heatmap_ax.get_yaxis()\n",
    "            # find the maximum width of the label on the major ticks\n",
    "            pad = max(T.label.get_window_extent().width for T in yax.majorTicks)\n",
    "            yax.set_tick_params(pad=pad)\n",
    "            heatmap_ax.set_ylabel('', rotation = 0)\n",
    "            heatmap_ax.set_title(sg)\n",
    "                    \n",
    "            bbox = heatmap_ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "            width, height = bbox.width, bbox.height\n",
    "\n",
    "            # TABLE\n",
    "            cell_text = []\n",
    "            for row in range(len(reads_df)):\n",
    "                cell_text.append(reads_df.iloc[row])\n",
    "            \n",
    "            if num_rows == 1: \n",
    "                table_ax = axs[1]\n",
    "            else: \n",
    "                table_ax = axs[row_count, 1]\n",
    "            #print('table position:', table_ax)\n",
    "            translations = list(heatmap_df['Label'])\n",
    "            #print(translations)\n",
    "            cell_height = height/(2*(len(translations)))\n",
    "\n",
    "            reads_table = table_ax.table(cellText=cell_text, colLabels=reads_df.columns, loc='center', cellLoc = 'center', edges = 'open')#, bbox = [0,0, width, height/2.3])\n",
    "            reads_table.auto_set_font_size(False)\n",
    "            reads_table.set_fontsize(12)\n",
    "            reads_table.auto_set_column_width(col=list(range(len(reads_df.columns))))\n",
    "            #reads_table.scale(1, 1.5)\n",
    "            cellDict = reads_table.get_celld()\n",
    "            \n",
    "            for i in range(0,len(reads_df.columns)):\n",
    "                cellDict[(0,i)].set_height(cell_height)\n",
    "                for j in range(1,len(reads_df)+1):\n",
    "                    cellDict[(j,i)].set_height(cell_height)\n",
    "            table_ax.set_axis_off()\n",
    "            \n",
    "\n",
    "            row_count+=1\n",
    "#             print(row_count)\n",
    "#             break\n",
    "    # Create path to Figures folder if doesn't exist already\n",
    "    Path(filepath + '/Figures/').mkdir(parents=True, exist_ok=True)\n",
    "    full_filepath = filepath + 'Figures/' + filename +'.pdf'\n",
    "    print(full_filepath)\n",
    "    plt.savefig(full_filepath,bbox_inches=\"tight\")\n",
    "\n",
    "hide_toggle(toggle_text_addon='heatmap function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User inputs\n",
    "\n",
    "<font color='blue'> Please follow steps indicated in blue, then run the notebook to generate output files. If the files are formatted as described in the documentation, the code in the 'Functions' section should not need to be altered. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metainformation file** \n",
    "\n",
    "<font color='blue'> <b>Step 1:</b> Create metainformation input file in the following format </font> \n",
    "\n",
    "**Columns**: \n",
    "\n",
    "* **sg** : sg identifier \n",
    "* **sgRNA_sequence** : sequence of sgRNA as designed \n",
    "* **translation_ref_seq**: reference sequence outputted by CRISPResso formatted such that any intronic sequences are lower-case, exons are upper-case, and UTRs are indicated by square brackets (if applicable) <u> must be sequence on strand that is being translated; may not necessarily be the same strand as the sgRNA sequence</u> \n",
    "    * Ex. <font color='grey'>tgtcttttctatgatctctttag</font><font color='green'>GGGTGACCCAGTCTATT</font>\n",
    "* **BEV_start** : BEV number for first sample in sg\n",
    "* **BEV_end** : BEV number for last sample in sg\n",
    "* **primer** : name of primer pair (joined by '\\_') used to amplify genomic locus as mentioned in sample name\n",
    "    * Ex. <font color='purple'>F_C12</font><font color = 'blue'><b>_</b></font><font color='green'>R_C12</font>\n",
    "* **frame** : frame for translation (manually determined for each sg / primer pair); position of first coding nucleotide in reference sequence within codon; frame can be 1, 2, 3\n",
    "    * Ex. given reference sequence: tgtcttttctatgatctctttag<font color='green'>**G**</font>G|GTG|ACC|CAG|TCT|ATT \n",
    "        since the first coding nucleotide of the reference sequence (<font color='green'><b>G</b></font>) is the 2nd nucleotide in its codon \n",
    "        (\\_<font color='green'><b>G</b></font>G) &rightarrow; frame = 2\n",
    "* **first_codon** : first codon for translation \n",
    "* **last_codon** : last codon for translation \n",
    "* **rev_com** : samples for which reference sequence is on reverse strand \n",
    "* **BEV_ref** : reference sample(s) for log-fold change (LFC) calculation (i.e. early time point, empty vector, etc.); if multiple BEV numbers are given, they should be separated by ';', and they will be treated as replicates that will be averaged\n",
    "* **BEV_test** : test sample(s) for LFC calculation; if multiple BEV numbers are given, they should be separated by ';', and they will be treated as replicates that will be averaged\n",
    "\n",
    "**Example input:**\n",
    "\n",
    "\n",
    "| sg      | sgRNA_sequence       | translation_ref_seq                                  | BEV_start | BEV_end | primer        | frame | first_codon| last_codon| rev_com | BEV_ref | BEV_test |\n",
    "| ------- | -------------------- | ---------------------------------------- |  -------: |  -----: | ------------- |  ----|----|---: | ------: | ------- | -------- |\n",
    "| 397   | GTCACCCCTAAAGAGATCAT | tgtcttttctatgatctctttagGGGTGACCCAGTCTATT | 7         | 12      |F_C12_R_C12 |  2    |TGG|ATT| True    | 5;6     | 9;10     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> <b> Step 1: </b> Enter filepath to metainformation input file here </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter input filepath here: ../../AudreyData/TP53/Metainfo_input_ABE_TP53_fixed_updated_1d_sample.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg</th>\n",
       "      <th>sgRNA_sequence</th>\n",
       "      <th>translation_ref_seq</th>\n",
       "      <th>BEV_start</th>\n",
       "      <th>BEV_end</th>\n",
       "      <th>primer</th>\n",
       "      <th>frame</th>\n",
       "      <th>first_codon</th>\n",
       "      <th>last_codon</th>\n",
       "      <th>rev_com</th>\n",
       "      <th>BEV_ref</th>\n",
       "      <th>BEV_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d</td>\n",
       "      <td>GCTCCTCCATGGCAGTGACC</td>\n",
       "      <td>[TTCCTCTTGCAGCAGCCAGACTGCCTTCCGGGTCACTGCC]ATGGAGGAGCCGCAGTCAGATCCTAGCGTCGAGCCCCCTC</td>\n",
       "      <td>417</td>\n",
       "      <td>426</td>\n",
       "      <td>F3_R2</td>\n",
       "      <td>1</td>\n",
       "      <td>ATG</td>\n",
       "      <td>CTG</td>\n",
       "      <td>True</td>\n",
       "      <td>417;418</td>\n",
       "      <td>425;426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sg        sgRNA_sequence  \\\n",
       "0  1d  GCTCCTCCATGGCAGTGACC   \n",
       "\n",
       "                                                                  translation_ref_seq  \\\n",
       "0  [TTCCTCTTGCAGCAGCCAGACTGCCTTCCGGGTCACTGCC]ATGGAGGAGCCGCAGTCAGATCCTAGCGTCGAGCCCCCTC   \n",
       "\n",
       "   BEV_start  BEV_end primer  frame first_codon last_codon  rev_com  BEV_ref  \\\n",
       "0        417      426  F3_R2      1         ATG        CTG     True  417;418   \n",
       "\n",
       "  BEV_test  \n",
       "0  425;426  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_file = pd.read_csv('../../AudreyData/TP53/Metainfo_input_ABE_TP53_fixed_updated.csv')\n",
    "input_filepath = input(\"Please enter input filepath here: \")\n",
    "input_file = pd.read_csv(input_filepath)\n",
    "input_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for NaN values i.e. blank rows\n",
    "if input_file.isnull().values.any(): \n",
    "    input_file = clean_input_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 726.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sg: 1d\n",
      "Translation reference sequence: [TTCCTCTTGCAGCAGCCAGACTGCCTTCCGGGTCACTGCC]ATGGAGGAGCCGCAGTCAGATCCTAGCGTCGAGCCCCCTC\n",
      "Translation input: ATGGAGGAGCCGCAGTCAGATCCTAGCGTCGAGCCCCCTC\n",
      "40 0\n",
      "1\n",
      "Expected WT Translation:  MEEPQSDPSVEPPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Input file is correct!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_input_file(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Metainformation file** \n",
    "\n",
    "<font color='blue'><b>Step 3:</b> Create correlation input file in the following format  </font> \n",
    "\n",
    "**Columns**: \n",
    "\n",
    "* **sg** : sg identifier \n",
    "* **reps_for_correlation** : semicolon-separated BEV numbers of which to calculate the pairwise Pearson correlation of the log-normalized read counts\n",
    "\n",
    "**Example input:**\n",
    "    \n",
    "| sg      | reps_for_correlation |\n",
    "| ------- | -------------------: | \n",
    "| 397     | 7;8 | \n",
    "| 397     | 9;10 | \n",
    "| 397     | 11;12 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Step 4:</b> Enter filepath to correlation input file here  </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter correlation input filepath here: ../../AudreyData/TP53/SampleCorrelation_input_TP53_ABE.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg</th>\n",
       "      <th>reps_for_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d</td>\n",
       "      <td>425;426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sg reps_for_correlation\n",
       "0  1d              425;426"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corr_input = pd.read_csv('../../AudreyData/TP53/SampleCorrelation_input_TP53_ABE.csv')\n",
    "corr_corr_inputpath = input(\"Please enter correlation input filepath here: \")\n",
    "corr_input = pd.read_csv(corr_corr_inputpath)\n",
    "corr_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify folder filepaths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Step 5:</b> Enter filepath to folder containing CRISPResso output files here. Please make sure that the filepath does not begin with a '/' but does end in a '/'.  </font> \n",
    "\n",
    "Please note that each folder containing CRISPResso output files for individual samples within the given folder should be named in the format 'CRISPResso_on_'+bev+'\\_'+\n",
    "primer, where bev = ('BEV' or 'NGBEV') + sample_number and primer = primer name. \n",
    "Ex. <font color='grey'>CRISPResso_on</font><font color='purple'>_BEV_001</font><font color='green'>_F2_R2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter either 'BEV' or 'NGBEV' to indicate which string is used when naming your CRISPResso files.NGBEV\n"
     ]
    }
   ],
   "source": [
    "global bev_string_id\n",
    "bev_string_id = input('Please enter either \\'BEV\\' or \\'NGBEV\\' to indicate which string is used when naming your CRISPResso files.')\n",
    "if ((bev_string_id != 'BEV') and (bev_string_id != 'NGBEV')):\n",
    "    raise Exception('Invalid input. Please enter either \\'BEV\\' or \\'NGBEV\\' to specify which string is used in CRISPResso file names. Be careful not to add any extra spaces.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter CRISPResso filepath here: ../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/\n"
     ]
    }
   ],
   "source": [
    "global CRISPResso_filepath \n",
    "# CRISPResso_filepath = '../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/'\n",
    "CRISPResso_filepath = input(\"Please enter CRISPResso filepath here: \")\n",
    "CRISPResso_filepath = check_folder_filepath(CRISPResso_filepath)\n",
    "print(CRISPResso_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Step 6:</b> Enter filepath to folder where the files generated by this notebook will be stored. Please make sure that the filepath does not begin with a '/' but does end in a '/'. If the folders in this file path do not currently exist, they will be created when the notebook is run.  </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter output folder filepath here: ../../AudreyData/TP53/ABE/\n",
      "../../AudreyData/TP53/ABE/\n"
     ]
    }
   ],
   "source": [
    "# Filepath to store allele_freq output tables \n",
    "global output_filepath \n",
    "# output_filepath = '../../AudreyData/TP53/ABE/'\n",
    "output_filepath = input(\"Please enter output folder filepath here: \")\n",
    "output_filepath = check_folder_filepath(output_filepath)\n",
    "print(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the two input files and produce allele tables for all sgRNAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d\n",
      "[('417', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('418', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('419', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('420', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('421', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('422', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('423', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('424', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('425', 'GCTCCTCCATGGCAGTGACC', 'F3_R2'), ('426', 'GCTCCTCCATGGCAGTGACC', 'F3_R2')]\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_417_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_418_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_419_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_420_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_421_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_422_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_423_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_424_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_425_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "../../AudreyData/TP53/TP53_ABE_Sample_CRISPResso/CRISPResso_on_NGBEV_426_F3_R2/Alleles_frequency_table_around_sgRNA_GCTCCTCCATGGCAGTGACC.txt\n",
      "['%Reads_BEV_417', '%Reads_BEV_418', '%Reads_BEV_419', '%Reads_BEV_420', '%Reads_BEV_421', '%Reads_BEV_422', '%Reads_BEV_423', '%Reads_BEV_424', '%Reads_BEV_425', '%Reads_BEV_426']\n",
      "only UTRs exist\n",
      "num rows in merge df: 24328\n",
      "                                                                      Aligned_Sequence  \\\n",
      "1493  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCATGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "1892  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCGTGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "2120  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCGTGGCGGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "2403  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCTTCCGTGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "\n",
      "                                                                    Reference_Sequence  \\\n",
      "1493  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCATGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "1892  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCATGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "2120  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCATGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "2403  GAGGGGGCTCGACGCTAGGATCTGACTGCGGCTCCTCCATGGCAGTGACCCGGAAGGCAGTCTGGCTGCTGCAAGAGGAA   \n",
      "\n",
      "      #Reads_BEV_417  %Reads_BEV_417  #Reads_BEV_418  %Reads_BEV_418  \\\n",
      "1493         25923.0       22.884206         32689.0       20.894883   \n",
      "1892         64999.0       57.379567         92961.0       59.420883   \n",
      "2120          3177.0        2.804580          4751.0        3.036850   \n",
      "2403          2334.0        2.060400          3524.0        2.252549   \n",
      "\n",
      "      #Reads_BEV_419  %Reads_BEV_419  #Reads_BEV_420  %Reads_BEV_420  ...  \\\n",
      "1493         55333.0       38.518513         42430.0       35.403177  ...   \n",
      "1892         58221.0       40.528913         50782.0       42.372005  ...   \n",
      "2120          4773.0        3.322590          4561.0        3.805654  ...   \n",
      "2403          3911.0        2.722533          3689.0        3.078066  ...   \n",
      "\n",
      "      #Reads_BEV_424;lognorm  #Reads_BEV_425;lognorm  #Reads_BEV_426;lognorm  \\\n",
      "1493               16.499275               19.031897               18.990468   \n",
      "1892               19.244084               17.996933               18.007661   \n",
      "2120               15.670348               14.914469               15.104924   \n",
      "2403               15.519962               14.620604               14.735993   \n",
      "\n",
      "      %read_count_filter  #read_count_filter             Translated     WT  \\\n",
      "1493                True                True         MEEPQSDPSVEPPL   True   \n",
      "1892                True                True         TEEPQSDPSVEPPL  False   \n",
      "2120                True                True  Possible UTR mutation  False   \n",
      "2403                True                True         TEEPQSDPSVEPPL  False   \n",
      "\n",
      "      LFC_425-417  LFC_426-418  AvgLFC_425_426  \n",
      "1493     1.227898     1.317671        1.272784  \n",
      "1892    -1.133247    -1.172952       -1.153099  \n",
      "2120     0.138921     0.214588        0.176754  \n",
      "2403     0.289897     0.276658        0.283278  \n",
      "\n",
      "[4 rows x 39 columns]\n",
      "96433.0\n",
      "133925.0\n",
      "122238.0\n",
      "101462.0\n",
      "27025.0\n",
      "18684.0\n",
      "144120.0\n",
      "136178.0\n",
      "71100.0\n",
      "54531.0\n"
     ]
    }
   ],
   "source": [
    "run(input_file,corr_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate allele-level heat maps annotated with corresponding allele amino acid sequences and tables with average % reads for each allele at early and late time points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, early time point samples are considered to be the same as the BEV_ref samples and the late time point samples are considered to be the BEV_test samples. If this is not the case (e.g.,  BEV_test samples span multiple time points), please upload a file with the following columns: \n",
    "\n",
    "**Columns**: \n",
    "\n",
    "* **sg** : sg identifier \n",
    "* **Time point** : string that identifies time point \n",
    "* **BEV_num** : semicolon-separated BEV numbers corresponding to samples at that time point \n",
    "\n",
    "**Example input:**\n",
    "    \n",
    "| sg      |time_point | BEV_nums |\n",
    "| ------- |------- | -------------------: | \n",
    "| 397     |D8      |  7;8 | \n",
    "| 397     |D14      | 9;10 | \n",
    "| 397     |D21      | 11;12 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the default time point sample assignments work for you? Please enter 'y' or 'n'. If 'n', you will be asked to enter the path to a time point input file as described above. Y\n"
     ]
    }
   ],
   "source": [
    "global timepoint_input_file\n",
    "\n",
    "# Check if default settings work for user\n",
    "default_y_or_n = input(\"Do the default time point sample assignments work for you? Please enter 'y' or 'n'. If 'n', you will be asked to enter the path to a time point input file as described above. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_y_or_n = default_y_or_n.lower()\n",
    "if default_y_or_n == 'y':\n",
    "    timepoint_input_file = None\n",
    "#     print('y')\n",
    "elif default_y_or_n == 'n':\n",
    "    timepoint_input_filepath = input(\"Please enter input filepath here: \")\n",
    "    # timepoint_input_file = pd.read_csv('AnnabelData/timepoint_df_test.csv')\n",
    "    timepoint_input_file = pd.read_csv(timepoint_input_filepath)\n",
    "#     print('n')\n",
    "else:\n",
    "    raise Exception('Invalid input. Please enter either \\'y\\' or \\'n\\' and re-run the cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../AudreyData/TP53/ABE/Figures/TP53_ABE_heatmap_1d.pdf\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmaps(df = input_file,\n",
    "         vmin = -2,\n",
    "         vmax = 2,\n",
    "         filepath = output_filepath,\n",
    "         time1 = 'D7',\n",
    "         time2 = 'D21',\n",
    "         timepoint_df = timepoint_input_file,\n",
    "         filename = 'TP53_ABE_heatmap_1d'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}